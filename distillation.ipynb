{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVHiUMDC55Do"
   },
   "source": [
    "# Travail préparatoire\n",
    "\n",
    "Avant de commencer le TP, nous vous recommandons fortement de :\n",
    "- Suivre le tutoriel [Customize what happens in Model.fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit)\n",
    "- Vous reporter si besoin à la documentation de la classe [``` Model ```](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njiSyopM0Phb"
   },
   "source": [
    "# Objectifs \n",
    "\n",
    "Les objectifs de ce TP sont : \n",
    "- Découvrir le principe de la compression des réseaux de neurones par distillation (cf: Hinton et al., [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531))\n",
    "\n",
    "- Illustrer la flexibilité du paradigme des réseaux de neurones profonds\n",
    "\n",
    "- Apprendre à utiliser la classe ``` Model ``` et à redéfinir certaines de ses méthodes (cf. travail préparatoire)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFFpwfOP6u-D"
   },
   "source": [
    "# Travail à réaliser \n",
    "\n",
    "Lors de ce TP, nous allons réaliser la distillation d'un réseau de neurones de type CNN (le *Teacher*) dans un réseau plus léger (le \"Student\"). Pour ce cas d'étude nous utiliserons la base MNIST que nous avons déjà utilisé lors des TP précédents. \n",
    "Vous allez donc devoir : \n",
    "- Définir l'architecture du réseau *Teacher* et optimiser le modèle sur la base MNIST (à noter que vous pouvez également utiliser un modèle pré-appris pour la tâche qui nous intéresse, ici la reconnaissance de chiffre manuscript)\n",
    "- Définir l'architecture du réseau léger *Student*\n",
    "- Préparer les données d'apprentissage qui serviront à la distillation. Nous utiliserons les données de MNIST (les mêmes que celles qui ont servi à l'apprentissage du Teacher, mais ce n'est pas une obligation, les deux bases peuvent être différentes, seules les tâches à réaliser doivent être identiques)\n",
    "- Implémenter la classe *Distiller* qui sera en charge de la distillation. \n",
    "\n",
    "La classe ``` Distiller ``` héritera de la classe ``` Model ``` pour laquelle il faudra redéfinir le constructeur, et les méthodes ``` train_step ``` et ``` test_step ```. Vous pourrez également redéfinir la méthode ``` compile ``` si vous souhaitez faire un code plus générique et tester différentes fonctions de coût et hyper-paramètre propre à la méthode de distillation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_y9Z1RjL0G3W"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOeaMjs1AYhX"
   },
   "source": [
    "## Préparation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oj5ek6I-AVks"
   },
   "outputs": [],
   "source": [
    "## Chargement et normalisation des données\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# POUR LES CNN : On rajoute une dimension pour spécifier qu'il s'agit d'images en NdG\n",
    "train_images = train_images.reshape(-1,28,28,1)\n",
    "test_images = test_images.reshape(-1,28,28,1)\n",
    "\n",
    "# One hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-YCwXQ9Bjbb"
   },
   "source": [
    "## Définition et apprentissage de modèle ```teacher```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atN9jNfVShYG"
   },
   "source": [
    "Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eK4PLyYyArHj"
   },
   "outputs": [],
   "source": [
    "## DEFINITION DES MODELES\n",
    "## Teacher \n",
    "## Définition de l'architecture du modèle\n",
    " \n",
    "# 16@3x3 -> AvPool -> 32@3x3 -> AvPool -> 64@3x3 -> AvPool -> FC 1024 -> FC 512\n",
    "teacher = tf.keras.models.Sequential()\n",
    "\n",
    "teacher.add(tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),padding=\"same\", activation='tanh', input_shape=(28, 28, 1)))\n",
    "teacher.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "teacher.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"valid\", activation='tanh'))\n",
    "teacher.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "teacher.add(tf.keras.layers.Flatten())\n",
    "\n",
    "teacher.add(tf.keras.layers.Dense(1024 , activation='tanh'))\n",
    "teacher.add(tf.keras.layers.Dense(512 , activation='tanh'))\n",
    "\n",
    "teacher.add(tf.keras.layers.Dense(10 , activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        9280      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,899,690\n",
      "Trainable params: 2,899,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(teacher.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygDhB7S5S1fS"
   },
   "source": [
    "Apprentissage du modèle (Adam + Entropie Croisée sur 10 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_teacher = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SQeuN3spSXmv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 53s 56ms/step - loss: 0.0075 - accuracy: 0.9974\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 54s 57ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 55s 59ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0099 - accuracy: 0.99660s - loss: 0.0099 - accuracy: 0.\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 56s 59ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 54s 58ms/step - loss: 0.0098 - accuracy: 0.9967\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 54s 57ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 53s 57ms/step - loss: 0.0112 - accuracy: 0.9962\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 53s 56ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 55s 58ms/step - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.0104 - accuracy: 0.9964\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 55s 58ms/step - loss: 0.0107 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 53s 56ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 53s 57ms/step - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 54s 58ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 56s 59ms/step - loss: 0.0092 - accuracy: 0.99660s - loss: 0.0092 - ac\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 55s 59ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 57s 60ms/step - loss: 0.0053 - accuracy: 0.9982\n"
     ]
    }
   ],
   "source": [
    "# Pour éviter d'apprendre à chaque fois le réseau Teacher, on l'enregistrer et \n",
    "# on le recharche si besoin\n",
    "\n",
    " \n",
    "if (load_teacher == True):\n",
    "    \n",
    "    # chargement du Teacher\n",
    "    teacher = keras.models.load_model('./teacher.h5')\n",
    "    \n",
    "else:\n",
    "    # Apprentissage du modèle Teacher\n",
    "    sgd = tf.keras.optimizers.Adam()\n",
    "    teacher.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    teacher.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=64,\n",
    "         epochs=20\n",
    "         )\n",
    "    \n",
    "    # Enregistrement du modele\n",
    "    teacher.save('./teacher.h5')\n",
    "    load_teacher == True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbycKD3hS-Au"
   },
   "source": [
    "Evaluation des performances sur la base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "AC09Fo-LTWD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0824 - accuracy: 0.9846\n",
      "Test accuracy: 0.9846000075340271\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = teacher.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TFf7vtFTgwm"
   },
   "source": [
    "## Définition du modèle  ```student```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7eusdDqyTpge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 8)         584       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 21,570\n",
      "Trainable params: 21,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Student\n",
    "student  = tf.keras.models.Sequential()\n",
    "\n",
    "student.add(tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),padding=\"same\", activation='tanh', input_shape=(28, 28, 1)))\n",
    "student.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "student.add(tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),padding=\"valid\", activation='tanh'))\n",
    "student.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "student.add(tf.keras.layers.Flatten())\n",
    "\n",
    "student.add(tf.keras.layers.Dense(64 , activation='tanh'))\n",
    "student.add(tf.keras.layers.Dense(32 , activation='tanh'))\n",
    "\n",
    "student.add(tf.keras.layers.Dense(10 , activation='softmax'))\n",
    "\n",
    "\n",
    "print(student.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gnYtj6Rey9hE"
   },
   "outputs": [],
   "source": [
    "# On copie l'instance pour comparer les différentes stratégies d'apprentissage \n",
    "student_loss_sup =  tf.keras.models.clone_model(student)\n",
    "student_loss_distillation =  tf.keras.models.clone_model(student)\n",
    "student_loss_both =  tf.keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tlWJGEdUCUj"
   },
   "source": [
    "## Définition de la classe ``` Distiller ```\n",
    " \n",
    "Le distiller a besoin du modèle ``` teacher ``` appris et de modèle ``` student ``` . Il a également besoin de parametres specifique à la distilation (eg. coeff de pondération des fonctions de coût) \n",
    " \n",
    "Les méthodes ``` train_step ``` et ``` test_step ``` doit être redéfinies et seront appelées respectivement par les méthodes ``` fit ``` et  ``` evaluate ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6KAUPyWbT350"
   },
   "outputs": [],
   "source": [
    "class Distiller(Model):\n",
    " \n",
    "    def __init__(self, teacher, student, coef):\n",
    "        super(Distiller, self).__init__()\n",
    "\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.coef = coef\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        \n",
    "        x,y = data\n",
    "        \n",
    "        y_teacher = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.student(x, training=True)\n",
    "            loss_sup = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "            loss_dist = self.compiled_loss(y_teacher, y_pred, regularization_losses=self.losses)\n",
    "            a = self.coef\n",
    "            loss = a * loss_dist + (1-a) *loss_sup\n",
    "            \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self.student(x, training=False)\n",
    "        \n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sjWOGz9XRi0"
   },
   "source": [
    "## Distillation du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DivT3clQXhHe"
   },
   "source": [
    "Apprentissage du modèle léger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cMh4Ob4eVlR5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 0.4720 - accuracy: 0.8671\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.1587 - accuracy: 0.9538\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 22s 45ms/step - loss: 0.1044 - accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.0798 - accuracy: 0.9770\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.0665 - accuracy: 0.9806\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0561 - accuracy: 0.9839\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0488 - accuracy: 0.9859\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0427 - accuracy: 0.9880\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0391 - accuracy: 0.98900s - loss: 0.0392 - accuracy: \n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0343 - accuracy: 0.9905\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0315 - accuracy: 0.9916\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0298 - accuracy: 0.9923\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0265 - accuracy: 0.9937\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 21s 43ms/step - loss: 0.0248 - accuracy: 0.9942\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0238 - accuracy: 0.9945\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0221 - accuracy: 0.9953\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0204 - accuracy: 0.9959\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0200 - accuracy: 0.9961\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0182 - accuracy: 0.9968\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0177 - accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b380ff57c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uniquement la loss superviée\n",
    "distiller = Distiller(teacher, student, 0)\n",
    "sgd = tf.keras.optimizers.Adam()\n",
    "distiller.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "distiller.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=120,\n",
    "         epochs=20\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imp9rVexXcNT"
   },
   "source": [
    "Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "soURiST-XeTg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9848\n",
      "Test accuracy: 0.9847999811172485\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = distiller.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "VQX6M-PFXqCa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 0.0182 - accuracy: 0.9963\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0169 - accuracy: 0.9961\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 0.0155 - accuracy: 0.9966\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0150 - accuracy: 0.9966\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.0143 - accuracy: 0.9966\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0128 - accuracy: 0.9973\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0134 - accuracy: 0.9969\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0130 - accuracy: 0.9968\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0124 - accuracy: 0.9970\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0122 - accuracy: 0.9970\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0116 - accuracy: 0.9972\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 23s 45ms/step - loss: 0.0111 - accuracy: 0.9974\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0105 - accuracy: 0.9973\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0100 - accuracy: 0.9976\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0106 - accuracy: 0.9974\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 22s 43ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0093 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b38120e988>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uniquement la loss distillation\n",
    "\n",
    "distiller = Distiller(teacher, student, 1)\n",
    "sgd = tf.keras.optimizers.Adam()\n",
    "distiller.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "distiller.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=120,\n",
    "         epochs=20\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9862\n",
      "Test accuracy: 0.9861999750137329\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = distiller.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "U3yAwsFN1_dp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
      "500/500 [==============================] - 18s 36ms/step - loss: 0.0098 - accuracy: 0.9976\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0088 - accuracy: 0.9984\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 20s 39ms/step - loss: 0.0081 - accuracy: 0.9987\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0078 - accuracy: 0.9988\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0097 - accuracy: 0.9979\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0074 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0075 - accuracy: 0.9990\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0070 - accuracy: 0.9992\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0095 - accuracy: 0.9981\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 20s 41ms/step - loss: 0.0064 - accuracy: 0.9992\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0070 - accuracy: 0.9989\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.0080 - accuracy: 0.9985\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 22s 45ms/step - loss: 0.0087 - accuracy: 0.9984\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 0.0077 - accuracy: 0.9987\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 0.0067 - accuracy: 0.9993\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 21s 41ms/step - loss: 0.0066 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.0081 - accuracy: 0.9984\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.0073 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b382657dc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# les 2 loss\n",
    "distiller = Distiller(teacher, student, 0.5)\n",
    "sgd = tf.keras.optimizers.Adam()\n",
    "distiller.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "distiller.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=120,\n",
    "         epochs=20\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ZkU-gwaI6Ttb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0581 - accuracy: 0.9853\n",
      "Test accuracy: 0.9853000044822693\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = distiller.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMKiPMxs9Hap"
   },
   "source": [
    "Dans ce TP, nous avons implémenté et évaluer une stratégie de distillation de l'information d'un réseau Teacher (expert) vers un réseau Student La distillation peut-être utilisée pour :\n",
    "- compresser la taille (nombre de paramètre) d'un réseau expert\n",
    "- spécialiser un réseau léger pour un domaine particulier\n",
    "- apprendre un réseau lorsque l'on dispose d'un (ou plusieurs) réseau mais pas de données annotées. \n",
    "\n",
    "\n",
    "Vous pouvez également tester cette stratégie sur : \n",
    "- d'autres bases (e.g. CIFAR 10)\n",
    "- en utilisant des réseaux pré-apris disponibles dans TF2 (eg: https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1) -> cf: https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub pour un exemple d'utilisation de modèles pré-appris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmq3uNMh-Kj7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP_distillation_a_completer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
